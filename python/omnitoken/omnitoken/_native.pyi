from typing import Dict, List, Tuple

class Tokenizer:
    vocab: Dict[str, float]
    vocab_to_ids: Dict[str, int]
    ids_to_vocab: Dict[int, str]
    def __init__(self, vocab: Dict[str, float]) -> None: ...
    def train(
        self, corpus: List[str], vocab_size: int, shrinking_factor: float
    ) -> None: ...
    def encode(
        self, text: str, mode: str | None
    ) -> Tuple[List[int], List[Tuple[int, int]]]: ...
    def decode(self, ids: List[int], mode: str | None) -> str: ...

class Model:
    tokenizer: Tokenizer
    def __init__(self, tokenizer: Tokenizer) -> None: ...
    def save(self, path: str) -> None: ...
    @staticmethod
    def load(path: str) -> Model: ...
